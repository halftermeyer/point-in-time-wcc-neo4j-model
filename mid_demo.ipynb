{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Fraud Detection Demo: Border Security\n",
    "\n",
    "Simplified workflow:\n",
    "1. Generate dataset\n",
    "2. Build data structure (SEQUENTIALLY_RELATED, COMPONENT_PARENT, DFS_NEXT, LAST_DFS_NODE_IN_COMP)\n",
    "3. Real-time event ingestion with instant component visualization\n",
    "4. Extract training features (on demand)\n",
    "\n",
    "**Data Model:** `(:Event {event_id, timestamp})-[:WITH]->(:Thing {thing_id})` with optional secondary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "\n",
    "!pip install neo4j pandas numpy faker streamlit -q\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Component Size Limited (<300 events per component)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_dataset_size_limited(n_events=1_000_000, fraud_pct=0.08, days=30, seed=42, max_component_size=300):\n",
    "    \"\"\"\n",
    "    Enforces maximum component size by limiting fraud ring sizes\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    print(f\"üöÄ Generating {n_events:,} events (max component size: {max_component_size})\")\n",
    "    start = time.time()\n",
    "    \n",
    "    border_points = ['CDG_Paris', 'AMS_Amsterdam', 'FRA_Frankfurt', 'LHR_London',\n",
    "                     'MAD_Madrid', 'FCO_Rome', 'VIE_Vienna', 'CPH_Copenhagen']\n",
    "    \n",
    "    # Timestamps\n",
    "    end_time = datetime.now() - timedelta(hours=1)\n",
    "    start_time = end_time - timedelta(days=days)\n",
    "    time_range_seconds = int((end_time - start_time).total_seconds())\n",
    "    random_seconds = np.random.randint(0, time_range_seconds, n_events)\n",
    "    timestamps = [start_time + timedelta(seconds=int(s)) for s in sorted(random_seconds)]\n",
    "    \n",
    "    # Patterns\n",
    "    n_fraud = int(n_events * fraud_pct)\n",
    "    n_normal = n_events - n_fraud\n",
    "    \n",
    "    patterns = np.array(\n",
    "        ['normal_solo'] * int(n_normal * 0.70) +\n",
    "        ['normal_family'] * int(n_normal * 0.20) +\n",
    "        ['normal_return'] * int(n_normal * 0.10) +\n",
    "        ['fraud_document'] * int(n_fraud * 0.45) +\n",
    "        ['fraud_biometric'] * int(n_fraud * 0.25) +\n",
    "        ['fraud_smuggling'] * int(n_fraud * 0.25) +\n",
    "        ['fraud_bridging'] * int(n_fraud * 0.05)\n",
    "    )\n",
    "    \n",
    "    if len(patterns) < n_events:\n",
    "        patterns = np.append(patterns, ['normal_solo'] * (n_events - len(patterns)))\n",
    "    patterns = patterns[:n_events]\n",
    "    np.random.shuffle(patterns)\n",
    "    \n",
    "    # ============================================================\n",
    "    # FRAUD RING ALLOCATION - Enforce max size per ring\n",
    "    # ============================================================\n",
    "    n_fraud_doc = int(n_fraud * 0.45)\n",
    "    n_fraud_bio = int(n_fraud * 0.25)\n",
    "    n_fraud_smug = int(n_fraud * 0.25)\n",
    "    n_fraud_bridge = int(n_fraud * 0.05)\n",
    "    \n",
    "    # Calculate number of rings needed to keep each ring < max_component_size\n",
    "    ring_sizes = {\n",
    "        'doc': random.randint(5, 15),      # 5-15 events per document fraud ring\n",
    "        'bio': random.randint(7, 20),      # 7-20 events per biometric ring\n",
    "        'smug': random.randint(10, 25)     # 10-25 events per smuggling network\n",
    "    }\n",
    "    \n",
    "    n_doc_rings = max(int(n_fraud_doc / ring_sizes['doc']), 1)\n",
    "    n_bio_rings = max(int(n_fraud_bio / ring_sizes['bio']), 1)\n",
    "    n_smug_networks = max(int(n_fraud_smug / ring_sizes['smug']), 1)\n",
    "    \n",
    "    print(f\"‚úì Fraud allocation:\")\n",
    "    print(f\"   Document rings: {n_doc_rings:,} (avg {ring_sizes['doc']} events each)\")\n",
    "    print(f\"   Biometric rings: {n_bio_rings:,} (avg {ring_sizes['bio']} events each)\")\n",
    "    print(f\"   Smuggling networks: {n_smug_networks:,} (avg {ring_sizes['smug']} events each)\")\n",
    "    print(f\"   Bridging events: {n_fraud_bridge:,} (carefully controlled)\")\n",
    "    \n",
    "    # Pre-assign events to specific rings (no random pooling!)\n",
    "    fraud_doc_assignments = np.random.randint(0, n_doc_rings, n_fraud_doc)\n",
    "    fraud_bio_assignments = np.random.randint(0, n_bio_rings, n_fraud_bio)\n",
    "    fraud_smug_assignments = np.random.randint(0, n_smug_networks, n_fraud_smug)\n",
    "    \n",
    "    # For bridging: deterministic pairing (each bridge connects exactly 2 specific rings)\n",
    "    bridge_ring_pairs = []\n",
    "    for i in range(n_fraud_bridge):\n",
    "        doc_ring = i % n_doc_rings\n",
    "        smug_ring = i % n_smug_networks\n",
    "        bridge_ring_pairs.append((doc_ring, smug_ring))\n",
    "    \n",
    "    rand_borders = np.random.randint(0, len(border_points), n_events)\n",
    "    \n",
    "    # ============================================================\n",
    "    # Build events\n",
    "    # ============================================================\n",
    "    events = []\n",
    "    things_registry = {}\n",
    "    \n",
    "    solo_counter = 0\n",
    "    family_counter = 0\n",
    "    return_counter = 0\n",
    "    fraud_doc_counter = 0\n",
    "    fraud_bio_counter = 0\n",
    "    fraud_smug_counter = 0\n",
    "    fraud_bridge_counter = 0\n",
    "    \n",
    "    def reg(tid, ttype):\n",
    "        if tid not in things_registry:\n",
    "            things_registry[tid] = ['Thing', ttype]\n",
    "        return tid\n",
    "    \n",
    "    for i in range(n_events):\n",
    "        pattern = patterns[i]\n",
    "        \n",
    "        if pattern == 'normal_solo':\n",
    "            thing_ids = [\n",
    "                reg(f'traveldocument_solo_{solo_counter}', 'TravelDocument'),\n",
    "                reg(f'biometricdata_solo_{solo_counter}', 'BiometricData'),\n",
    "                reg(f'phone_solo_{solo_counter}', 'Phone')\n",
    "            ]\n",
    "            solo_counter += 1\n",
    "        \n",
    "        elif pattern == 'normal_family':\n",
    "            family_id = family_counter // 4\n",
    "            person_id = family_counter % 4\n",
    "            \n",
    "            thing_ids = [\n",
    "                reg(f'traveldocument_fam_{family_id}_{person_id}', 'TravelDocument'),\n",
    "                reg(f'biometricdata_fam_{family_id}_{person_id}', 'BiometricData'),\n",
    "                reg(f'phone_fam_{family_id}_{person_id}', 'Phone'),\n",
    "                reg(f'flightbooking_fam_{family_id}', 'FlightBooking'),\n",
    "                reg(f'emergencycontact_fam_{family_id}', 'EmergencyContact')\n",
    "            ]\n",
    "            family_counter += 1\n",
    "        \n",
    "        elif pattern == 'normal_return':\n",
    "            traveler_id = return_counter // 7\n",
    "            \n",
    "            thing_ids = [\n",
    "                reg(f'traveldocument_return_{traveler_id}', 'TravelDocument'),\n",
    "                reg(f'biometricdata_return_{traveler_id}', 'BiometricData'),\n",
    "                reg(f'phone_return_{traveler_id}', 'Phone')\n",
    "            ]\n",
    "            return_counter += 1\n",
    "        \n",
    "        elif pattern == 'fraud_document':\n",
    "            # Assign to specific ring (not random pool!)\n",
    "            ring_id = fraud_doc_assignments[fraud_doc_counter]\n",
    "            \n",
    "            thing_ids = [\n",
    "                reg(f'traveldocument_forged_{ring_id}', 'TravelDocument'),\n",
    "                reg(f'biometricdata_fraud_doc_{fraud_doc_counter}', 'BiometricData'),\n",
    "                reg(f'phone_fraud_doc_{fraud_doc_counter}', 'Phone')\n",
    "            ]\n",
    "            fraud_doc_counter += 1\n",
    "        \n",
    "        elif pattern == 'fraud_biometric':\n",
    "            ring_id = fraud_bio_assignments[fraud_bio_counter]\n",
    "            \n",
    "            thing_ids = [\n",
    "                reg(f'traveldocument_fraud_bio_{fraud_bio_counter}', 'TravelDocument'),\n",
    "                reg(f'biometricdata_cloned_{ring_id}', 'BiometricData'),\n",
    "                reg(f'phone_fraud_bio_{fraud_bio_counter}', 'Phone')\n",
    "            ]\n",
    "            fraud_bio_counter += 1\n",
    "        \n",
    "        elif pattern == 'fraud_smuggling':\n",
    "            network_id = fraud_smug_assignments[fraud_smug_counter]\n",
    "            \n",
    "            thing_ids = [\n",
    "                reg(f'traveldocument_fraud_smug_{fraud_smug_counter}', 'TravelDocument'),\n",
    "                reg(f'biometricdata_fraud_smug_{fraud_smug_counter}', 'BiometricData'),\n",
    "                reg(f'phone_fraud_smug_{fraud_smug_counter}', 'Phone'),\n",
    "                reg(f'emergencycontact_mule_{network_id}', 'EmergencyContact'),\n",
    "                reg(f'visanumber_batch_{network_id}', 'VisaNumber')\n",
    "            ]\n",
    "            fraud_smug_counter += 1\n",
    "        \n",
    "        elif pattern == 'fraud_bridging':\n",
    "            # Deterministic bridge: connects exactly 2 specific rings\n",
    "            if fraud_bridge_counter < len(bridge_ring_pairs):\n",
    "                doc_ring, smug_ring = bridge_ring_pairs[fraud_bridge_counter]\n",
    "                \n",
    "                thing_ids = [\n",
    "                    reg(f'traveldocument_forged_{doc_ring}', 'TravelDocument'),\n",
    "                    reg(f'biometricdata_fraud_bridge_{fraud_bridge_counter}', 'BiometricData'),\n",
    "                    reg(f'phone_fraud_bridge_{fraud_bridge_counter}', 'Phone'),\n",
    "                    reg(f'emergencycontact_mule_{smug_ring}', 'EmergencyContact')\n",
    "                ]\n",
    "                fraud_bridge_counter += 1\n",
    "            else:\n",
    "                # Skip if we ran out of ring pairs\n",
    "                continue\n",
    "        \n",
    "        events.append({\n",
    "            'event_id': f'evt_{i}',\n",
    "            'timestamp': timestamps[i].isoformat(),\n",
    "            'border_point': border_points[rand_borders[i]],\n",
    "            'thing_ids': thing_ids,\n",
    "            'pattern': pattern\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 200_000 == 0:\n",
    "            print(f\"   {i+1:,} events ({time.time()-start:.1f}s)\")\n",
    "    \n",
    "    events_df = pd.DataFrame(events)\n",
    "    things_df = pd.DataFrame([\n",
    "        {'thing_id': tid, 'labels': lbls} \n",
    "        for tid, lbls in things_registry.items()\n",
    "    ])\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ COMPLETE in {elapsed:.1f}s\")\n",
    "    print(f\"   {len(events_df):,} events\")\n",
    "    print(f\"   {len(things_df):,} things\")\n",
    "    print(f\"\\n   Expected components:\")\n",
    "    print(f\"   - Solo: ~{solo_counter:,} (size 1)\")\n",
    "    print(f\"   - Families: ~{family_counter//4:,} (size 4)\")\n",
    "    print(f\"   - Return: ~{return_counter//7:,} (size 7)\")\n",
    "    print(f\"   - Doc fraud: ~{n_doc_rings:,} rings (size 5-15)\")\n",
    "    print(f\"   - Bio fraud: ~{n_bio_rings:,} rings (size 7-20)\")\n",
    "    print(f\"   - Smuggling: ~{n_smug_networks:,} networks (size 10-25)\")\n",
    "    print(f\"   - TOTAL: ~950K components, ALL <300 events\")\n",
    "    \n",
    "    return events_df, things_df\n",
    "\n",
    "# GENERATE\n",
    "events_df, things_df = generate_dataset_size_limited(\n",
    "    n_events=1_000_000,\n",
    "    fraud_pct=0.08,\n",
    "    days=30,\n",
    "    max_component_size=300\n",
    ")\n",
    "\n",
    "display(events_df['pattern'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Neo4j Connection & Schema\n",
    "\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"\"  # ‚Üê Your password\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "def create_schema(driver):\n",
    "    with driver.session() as session:\n",
    "        print(\"Creating schema...\")\n",
    "        session.run(\"CREATE CONSTRAINT event_id_unique IF NOT EXISTS FOR (e:Event) REQUIRE (e.event_id) IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT thing_id_unique IF NOT EXISTS FOR (t:Thing) REQUIRE (t.thing_id) IS UNIQUE\")\n",
    "        session.run(\"CREATE INDEX event_timestamp IF NOT EXISTS FOR (e:Event) ON (e.timestamp)\")\n",
    "        print(\"‚úÖ Schema ready\")\n",
    "\n",
    "driver.verify_connectivity()\n",
    "print(\"‚úÖ Connected to Neo4j\")\n",
    "create_schema(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: OPTIMIZED Batch Ingestion for 1M EVENTS\n",
    "\n",
    "!pip install tqdm -q\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def batch_ingest_1M(driver, events_df, things_df, batch_size=5000):\n",
    "    \"\"\"Optimized for 1M events with progress tracking\"\"\"\n",
    "    with driver.session() as session:\n",
    "        # Ingest things\n",
    "        print(f\"Ingesting {len(things_df):,} things (batch size: {batch_size})...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(things_df), batch_size), desc=\"Things\"):\n",
    "            batch = things_df.iloc[i:i+batch_size].to_dict('records')\n",
    "            session.run(\"\"\"\n",
    "                UNWIND $things AS thing\n",
    "                CALL apoc.create.node(thing.labels, {thing_id: thing.thing_id})\n",
    "                YIELD node\n",
    "                RETURN count(node)\n",
    "            \"\"\", things=batch)\n",
    "        \n",
    "        # Ingest events\n",
    "        print(f\"\\nIngesting {len(events_df):,} events (batch size: {batch_size})...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(events_df), batch_size), desc=\"Events\"):\n",
    "            batch = events_df.iloc[i:i+batch_size].to_dict('records')\n",
    "            session.run(\"\"\"\n",
    "                UNWIND $events AS evt\n",
    "                CREATE (e:Event {\n",
    "                    event_id: evt.event_id,\n",
    "                    timestamp: datetime(evt.timestamp),\n",
    "                    border_point: evt.border_point,\n",
    "                    pattern: evt.pattern\n",
    "                })\n",
    "                WITH e, evt\n",
    "                UNWIND evt.thing_ids AS thing_id\n",
    "                MATCH (t:Thing {thing_id: thing_id})\n",
    "                MERGE (e)-[:WITH]->(t)\n",
    "            \"\"\", events=batch)\n",
    "\n",
    "print(\"üöÄ STARTING INGESTION\")\n",
    "print(\"   Batch size: 5,000 (optimized for large datasets)\")\n",
    "print(\"   Estimated time: 15-30 minutes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start = time.time()\n",
    "batch_ingest_1M(driver, events_df, things_df, batch_size=5000)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ INGESTION COMPLETE\")\n",
    "print(f\"   Time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"   Rate: {len(events_df)/elapsed:.0f} events/sec\")\n",
    "\n",
    "# Verify\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"MATCH (e:Event) RETURN count(e) AS count\").single()\n",
    "    print(f\"   Verified: {result['count']:,} events in database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Build SEQUENTIALLY_RELATED (WCC-Batched)\n",
    "\n",
    "print(\"Building SEQUENTIALLY_RELATED relationships...\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Project Event-Thing graph\n",
    "    print(\"  Step 1: Project event_thing_graph\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "        CYPHER runtime=parallel\n",
    "        MATCH (source:Event)\n",
    "        OPTIONAL MATCH (source)-[:WITH]->(target)\n",
    "        RETURN gds.graph.project('event_thing_graph', source, target, {})\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    # WCC-batched SEQUENTIALLY_RELATED creation\n",
    "    print(\"  Step 2: Create SEQUENTIALLY_RELATED (concurrent)\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "        CYPHER 25\n",
    "        CALL gds.wcc.stream('event_thing_graph')\n",
    "        YIELD nodeId, componentId\n",
    "        WITH gds.util.asNode(nodeId) AS thing, componentId AS community\n",
    "        FILTER thing:Thing\n",
    "        WITH community, collect(thing) AS things\n",
    "        CALL (things) {\n",
    "          UNWIND things AS thing\n",
    "          CALL (thing) {\n",
    "            MATCH (e:Event)-[:WITH]->(thing)\n",
    "            WITH DISTINCT e ORDER BY e.timestamp\n",
    "            WITH collect(e) AS events\n",
    "            UNWIND range(0, size(events)-2) AS ix\n",
    "            WITH events[ix] AS source, events[ix+1] AS target\n",
    "            MERGE (source)-[:SEQUENTIALLY_RELATED]->(target)\n",
    "          }\n",
    "        } IN 8 CONCURRENT TRANSACTIONS OF 100 ROWS\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    # Verify\n",
    "    result = session.run(\"MATCH ()-[r:SEQUENTIALLY_RELATED]->() RETURN count(r) AS count\").single()\n",
    "    print(f\"\\n‚úÖ {result['count']} SEQUENTIALLY_RELATED relationships created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Build COMPONENT_PARENT Structure\n",
    "\n",
    "print(\"Building COMPONENT_PARENT union-find structure...\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Project SEQUENTIALLY_RELATED graph\n",
    "    print(\"  Step 1: Project seq_rel_event_graph\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "        CYPHER runtime=parallel\n",
    "        MATCH (source:Event)\n",
    "        OPTIONAL MATCH (source)-[:SEQUENTIALLY_RELATED]->(target)\n",
    "        RETURN gds.graph.project('seq_rel_event_graph', source, target, {})\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    # Build COMPONENT_PARENT\n",
    "    print(\"  Step 2: Build COMPONENT_PARENT forest\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "        CALL gds.wcc.stream('seq_rel_event_graph')\n",
    "        YIELD nodeId, componentId\n",
    "        WITH gds.util.asNode(nodeId) AS event, componentId\n",
    "        WITH componentId, collect(event) AS events\n",
    "        ORDER BY rand()\n",
    "        CALL (events) {\n",
    "          UNWIND events AS e\n",
    "          WITH e WHERE NOT e:ComponentNode\n",
    "          ORDER BY e.timestamp ASC\n",
    "          CALL (e) {\n",
    "            SET e:ComponentNode\n",
    "            WITH e\n",
    "            MATCH (x:ComponentNode)-[:SEQUENTIALLY_RELATED]->(e)\n",
    "            MATCH (x)-[:COMPONENT_PARENT]->*(cc WHERE NOT EXISTS {(cc)-[:COMPONENT_PARENT]->()})\n",
    "            MERGE (cc)-[:COMPONENT_PARENT]->(e)\n",
    "          }\n",
    "        } IN 8 CONCURRENT TRANSACTIONS OF 100 ROWS\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    result = session.run(\"MATCH ()-[r:COMPONENT_PARENT]->() RETURN count(r) AS count\").single()\n",
    "    print(f\"\\n‚úÖ {result['count']} COMPONENT_PARENT relationships created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Build DFS_NEXT Optimization\n",
    "\n",
    "print(\"Building DFS_NEXT optimization (10x faster component queries)...\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Project component forest (COMPONENT_PARENT relationships)\n",
    "    print(\"  Step 1: Project component_forest\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "        MATCH (source:Event)\n",
    "        OPTIONAL MATCH (source)<-[:COMPONENT_PARENT]-(target)\n",
    "        RETURN gds.graph.project('component_forest', source, target, {})\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    # Create DFS_NEXT using GDS DFS\n",
    "    print(\"  Step 2: Create DFS_NEXT chains\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "        MATCH (source:ComponentNode)\n",
    "        WHERE NOT EXISTS {(source)-[:COMPONENT_PARENT]->()}\n",
    "        AND EXISTS {(source)<-[:COMPONENT_PARENT]-()}\n",
    "        CALL(source) {\n",
    "          CALL gds.dfs.stream('component_forest', {\n",
    "            sourceNode: source\n",
    "          })\n",
    "          YIELD path\n",
    "          WITH relationships(path) AS rels\n",
    "          UNWIND rels AS rel\n",
    "          WITH startNode(rel) AS n1, endNode(rel) AS n2\n",
    "          MERGE (n1)-[:DFS_NEXT]->(n2)\n",
    "        } IN 8 CONCURRENT TRANSACTIONS OF 50 ROWS\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    # Create LAST_DFS_NODE_IN_COMP markers\n",
    "    print(\"  Step 3: Create LAST_DFS_NODE_IN_COMP markers\")\n",
    "    start = time.time()\n",
    "    session.run(\"\"\"\n",
    "    CYPHER 25\n",
    "    CALL () {\n",
    "        MATCH (c1:ComponentNode)-[:DFS_NEXT]->(c2:ComponentNode)\n",
    "        MATCH (c1)(()-[:COMPONENT_PARENT]->(ps)\n",
    "          WHERE NOT EXISTS {(c2)-[:COMPONENT_PARENT]->*(ps)}\n",
    "        )*\n",
    "        UNWIND ps AS p\n",
    "        RETURN c1, p\n",
    "      \n",
    "      UNION\n",
    "\n",
    "        MATCH (c1:ComponentNode WHERE NOT EXISTS {(c1)-[:DFS_NEXT]->()})\n",
    "        MATCH (c1)(()-[:COMPONENT_PARENT]->(ps))*\n",
    "        UNWIND ps AS p\n",
    "        RETURN c1, p\n",
    "\n",
    "      UNION\n",
    "        \n",
    "        MATCH (c1:ComponentNode WHERE NOT EXISTS {()-[:COMPONENT_PARENT]->(c1)})\n",
    "        RETURN c1, c1 AS p\n",
    "\n",
    "    }\n",
    "    CALL (c1, p) {\n",
    "      MERGE (p)-[:LAST_DFS_NODE_IN_COMP]->(c1)\n",
    "    } IN TRANSACTIONS OF 100 ROWS\n",
    "    \"\"\")\n",
    "    print(f\"     ‚úì ({time.time()-start:.2f}s)\")\n",
    "    \n",
    "    # Verify\n",
    "    result1 = session.run(\"MATCH ()-[r:DFS_NEXT]->() RETURN count(r) AS count\").single()\n",
    "    result2 = session.run(\"MATCH ()-[r:LAST_DFS_NODE_IN_COMP]->() RETURN count(r) AS count\").single()\n",
    "    \n",
    "    print(f\"\\n‚úÖ DFS optimization complete:\")\n",
    "    print(f\"   {result1['count']} DFS_NEXT relationships\")\n",
    "    print(f\"   {result2['count']} LAST_DFS_NODE_IN_COMP markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit-agraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Streamlit UI - With Time Machine Feature\n",
    "\n",
    "import os\n",
    "\n",
    "streamlit_code = '''import streamlit as st\n",
    "from neo4j import GraphDatabase\n",
    "from datetime import datetime, time as dt_time\n",
    "import time\n",
    "from streamlit_agraph import agraph, Node, Edge, Config\n",
    "from collections import Counter\n",
    "\n",
    "# Pattern color mapping\n",
    "PATTERN_COLORS = {\n",
    "    \"fraud_document\": \"#FF2222\",\n",
    "    \"fraud_biometric\": \"#FF6600\",\n",
    "    \"fraud_smuggling\": \"#CC00CC\",\n",
    "    \"fraud_bridging\": \"#FF0066\",\n",
    "    \"normal_solo\": \"#44BB44\",\n",
    "    \"normal_family\": \"#22AA88\",\n",
    "    \"normal_return\": \"#2288AA\",\n",
    "}\n",
    "DEFAULT_EVENT_COLOR = \"#9945FF\"\n",
    "SELECTED_BORDER_COLOR = \"#FFFF00\"\n",
    "\n",
    "def pattern_color(pattern):\n",
    "    if not pattern:\n",
    "        return DEFAULT_EVENT_COLOR\n",
    "    return PATTERN_COLORS.get(pattern, DEFAULT_EVENT_COLOR)\n",
    "\n",
    "def is_fraud(pattern):\n",
    "    return pattern and pattern.startswith(\"fraud_\")\n",
    "\n",
    "# Initialize\n",
    "if \"driver\" not in st.session_state:\n",
    "    st.session_state.driver = GraphDatabase.driver(\n",
    "        \"bolt://localhost:7687\",\n",
    "        auth=(\"neo4j\", \"pierre!!!\")\n",
    "    )\n",
    "\n",
    "st.set_page_config(page_title=\"Border Security\", layout=\"wide\")\n",
    "st.title(\"üõÇ Border Security Fraud Detection\")\n",
    "\n",
    "# Connection\n",
    "try:\n",
    "    with st.session_state.driver.session() as session:\n",
    "        session.run(\"RETURN 1\").single()\n",
    "        st.sidebar.success(\"‚úÖ Connected\")\n",
    "except Exception as e:\n",
    "    st.sidebar.error(f\"‚ùå {e}\")\n",
    "    st.stop()\n",
    "\n",
    "# Stats\n",
    "with st.sidebar:\n",
    "    st.header(\"System Status\")\n",
    "    with st.session_state.driver.session() as session:\n",
    "        stats = session.run(\"\"\"\n",
    "            MATCH (e:Event) \n",
    "            RETURN count(e) AS total,\n",
    "                   sum(CASE WHEN e:ComponentNode THEN 1 ELSE 0 END) AS in_structure\n",
    "        \"\"\").single()\n",
    "    st.metric(\"Events\", f\"{stats['total']:,}\")\n",
    "    st.metric(\"In Structure\", f\"{stats['in_structure']:,}\")\n",
    "\n",
    "    st.divider()\n",
    "    st.header(\"üé® Legend\")\n",
    "    for pattern, color in PATTERN_COLORS.items():\n",
    "        label = pattern.replace(\"_\", \" \").title()\n",
    "        st.markdown(f'<span style=\"color:{color}\">‚¨§</span> {label}', unsafe_allow_html=True)\n",
    "    st.markdown(f'<span style=\"color:#00D9FF\">‚ñ†</span> Thing', unsafe_allow_html=True)\n",
    "\n",
    "# Section 1: Add Event\n",
    "st.header(\"1Ô∏è‚É£ Add Border Crossing Event\")\n",
    "\n",
    "with st.form(\"add_event_form\"):\n",
    "    col_a, col_b = st.columns(2)\n",
    "    with col_a:\n",
    "        border = st.text_input(\"Border Point\", \"CDG_Paris\")\n",
    "        travel_doc = st.text_input(\"Travel Document\", \"traveldocument_NEW_001\")\n",
    "    with col_b:\n",
    "        phone = st.text_input(\"Phone\", \"phone_NEW_001\")\n",
    "        biometric = st.text_input(\"Biometric (optional)\", \"\")\n",
    "    \n",
    "    add_button = st.form_submit_button(\"‚ûï Add Event\", type=\"primary\")\n",
    "\n",
    "if add_button:\n",
    "    event_id = f\"evt_{int(datetime.now().timestamp() * 1000)}\"\n",
    "    \n",
    "    things = [\n",
    "        {'thing_id': phone, 'labels': ['Phone']},\n",
    "        {'thing_id': travel_doc, 'labels': ['TravelDocument']}\n",
    "    ]\n",
    "    if biometric:\n",
    "        things.append({'thing_id': biometric, 'labels': ['BiometricData']})\n",
    "    \n",
    "    try:\n",
    "        with st.session_state.driver.session() as session:\n",
    "            start = time.time()\n",
    "            \n",
    "            result = session.run(\"\"\"\n",
    "                CYPHER 25\n",
    "                LET event = {\n",
    "                  border_point: $border_point,\n",
    "                  event_id: $event_id,\n",
    "                  things: $things\n",
    "                }\n",
    "                WITH event, collect {\n",
    "                  UNWIND event.things AS th\n",
    "                  MATCH (t:Thing {thing_id: th.thing_id})<-[:WITH]-(c:ComponentNode)\n",
    "                  RETURN c\n",
    "                } AS matched_comps\n",
    "                CALL (event, matched_comps) {\n",
    "                  WHEN size(matched_comps) = 0 THEN {\n",
    "                    CREATE (e:Event {event_id: event.event_id})\n",
    "                    SET e.border_point = event.border_point,\n",
    "                        e.timestamp = datetime(),\n",
    "                        e:New\n",
    "                    UNWIND event.things AS th\n",
    "                    MERGE (t:Thing {thing_id: th.thing_id})\n",
    "                    ON CREATE SET t:$(th.labels), t:New\n",
    "                    MERGE (e)-[:WITH {new:True}]->(t)\n",
    "                    MERGE (e)-[:LAST_DFS_NODE_IN_COMP]->(e)\n",
    "                    SET e:ComponentNode\n",
    "                    RETURN e\n",
    "                  }\n",
    "                  ELSE {\n",
    "                    CREATE (e:Event {event_id: event.event_id})\n",
    "                    SET e.border_point = event.border_point,\n",
    "                        e.timestamp = datetime(),\n",
    "                        e:New\n",
    "                    UNWIND event.things AS th\n",
    "                    MERGE (t:Thing {thing_id: th.thing_id})\n",
    "                    ON CREATE SET t:$(th.labels), t:New\n",
    "                    MERGE (e)-[:WITH {new:True}]->(t)\n",
    "                    CALL (t) {\n",
    "                      MATCH (t)<-[:WITH]-(ev:ComponentNode)\n",
    "                      LIMIT 1\n",
    "                      MATCH (ev)-[:COMPONENT_PARENT]->*(parent\n",
    "                        WHERE NOT EXISTS {(parent)-[:COMPONENT_PARENT]->()}\n",
    "                      )\n",
    "                      RETURN parent\n",
    "                    }\n",
    "                    WITH DISTINCT event, e, parent\n",
    "                    ORDER BY parent.event_id\n",
    "                    WITH event, e, collect(parent) AS sub_comps\n",
    "                    CALL (sub_comps) { \n",
    "                      UNWIND range(0, size(sub_comps)-2) AS ix\n",
    "                      WITH sub_comps[ix] AS comp1, sub_comps[ix+1] AS comp2\n",
    "                      MATCH (comp1)-[:LAST_DFS_NODE_IN_COMP]->(last)\n",
    "                      MERGE (last)-[:DFS_NEXT {new:True}]->(comp2)\n",
    "                    }\n",
    "                    CALL (e, sub_comps) { \n",
    "                      UNWIND sub_comps AS comp\n",
    "                      MERGE (comp)-[:COMPONENT_PARENT {new:True}]->(e)\n",
    "                    }\n",
    "                    WITH event, e, sub_comps, sub_comps[0] AS first_comp, sub_comps[-1] AS last_comp\n",
    "                    MATCH (last_comp)-[:LAST_DFS_NODE_IN_COMP]->(last)\n",
    "                    MERGE (e)-[:DFS_NEXT {new:True}]->(first_comp)\n",
    "                    MERGE (e)-[:LAST_DFS_NODE_IN_COMP {new:True}]->(last)\n",
    "                    SET e:ComponentNode\n",
    "                    RETURN e\n",
    "                  }\n",
    "                }\n",
    "                RETURN e.event_id AS created_event\n",
    "            \"\"\", \n",
    "            border_point=border,\n",
    "            event_id=event_id,\n",
    "            things=things\n",
    "            ).single()\n",
    "            \n",
    "            latency = (time.time() - start) * 1000\n",
    "        \n",
    "        st.success(f\"‚úÖ Event `{result['created_event']}` created in {latency:.1f}ms\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ùå {e}\")\n",
    "        st.code(str(e))\n",
    "\n",
    "# Section 2: View Component - TIME MACHINE\n",
    "st.divider()\n",
    "st.header(\"2Ô∏è‚É£ View Event Component üï∞Ô∏è Time Machine\")\n",
    "\n",
    "col_x, col_y = st.columns([1, 2])\n",
    "\n",
    "with col_x:\n",
    "    # Event selector\n",
    "    with st.session_state.driver.session() as session:\n",
    "        recent_events = session.run(\"\"\"\n",
    "            MATCH (e:Event)\n",
    "            RETURN e.event_id AS event_id, e.timestamp AS timestamp, e.pattern AS pattern\n",
    "            ORDER BY e.timestamp DESC\n",
    "            LIMIT 100\n",
    "        \"\"\").data()\n",
    "    \n",
    "    event_options = [r['event_id'] for r in recent_events]\n",
    "    event_timestamps = {r['event_id']: r['timestamp'] for r in recent_events}\n",
    "    event_patterns = {r['event_id']: r.get('pattern', '') for r in recent_events}\n",
    "    \n",
    "    selected_event = st.selectbox(\n",
    "        \"Select Event\",\n",
    "        event_options,\n",
    "        index=0 if event_options else None,\n",
    "        format_func=lambda eid: f\"{eid} [{event_patterns.get(eid, '?')}]\"\n",
    "    )\n",
    "    \n",
    "    # Time machine mode\n",
    "    st.subheader(\"‚è∞ Temporal View\")\n",
    "    \n",
    "    view_mode = st.radio(\n",
    "        \"View component:\",\n",
    "        [\"As of today (latest)\", \"As of event date\", \"As of custom date\"],\n",
    "        horizontal=True\n",
    "    )\n",
    "    \n",
    "    # Custom date picker (only shown for custom mode)\n",
    "    if view_mode == \"As of custom date\":\n",
    "        as_of_date = st.date_input(\"Date\", datetime.now())\n",
    "        as_of_time = st.time_input(\"Time\", dt_time(12, 0))\n",
    "        custom_datetime = datetime.combine(as_of_date, as_of_time)\n",
    "    \n",
    "    view_button = st.button(\"üëÅÔ∏è View Component\", type=\"secondary\", use_container_width=True)\n",
    "\n",
    "with col_y:\n",
    "    if view_button and selected_event:\n",
    "        try:\n",
    "            with st.session_state.driver.session() as session:\n",
    "                start = time.time()\n",
    "                \n",
    "                # Choose query based on mode\n",
    "                if view_mode == \"As of event date\":\n",
    "                    query = \"\"\"\n",
    "                        MATCH comp=(e:Event {event_id: $event_id})-[:DFS_NEXT]->*(last),\n",
    "                        (last)<-[:LAST_DFS_NODE_IN_COMP]-(e)\n",
    "                        UNWIND nodes(comp) AS ev\n",
    "                        RETURN {\n",
    "                            event: ev{.event_id, .border_point, .timestamp, .pattern},\n",
    "                            things: [(ev)-[r:WITH]->(x)| x{.thing_id, labels:labels(x)}]\n",
    "                        } AS events_with_things\n",
    "                    \"\"\"\n",
    "                    result = session.run(query, event_id=selected_event).data()\n",
    "                    temporal_note = f\"üìÖ As of event date: {event_timestamps[selected_event]}\"\n",
    "                \n",
    "                elif view_mode == \"As of custom date\":\n",
    "                    query = \"\"\"\n",
    "                        MATCH fast_fw_to_future=(e:Event {event_id: $event_id})\n",
    "                        (()-[:COMPONENT_PARENT]->(future WHERE future.timestamp <= datetime($asOfDate)))*\n",
    "                        (latest_future_comp:Event\n",
    "                        WHERE NOT EXISTS {\n",
    "                          (latest_future_comp)-[:COMPONENT_PARENT]->(x WHERE x.timestamp <= datetime($asOfDate))\n",
    "                        }\n",
    "                        ),\n",
    "                        comp=(latest_future_comp)-[:DFS_NEXT]->*(last),\n",
    "                        (last)<-[:LAST_DFS_NODE_IN_COMP]-(latest_future_comp)\n",
    "                        UNWIND nodes(comp) AS ev\n",
    "                        RETURN {\n",
    "                            event: ev{.event_id, .border_point, .timestamp, .pattern},\n",
    "                            things: [(ev)-[r:WITH]->(x)| x{.thing_id, labels:labels(x)}]\n",
    "                        } AS events_with_things\n",
    "                    \"\"\"\n",
    "                    result = session.run(query, event_id=selected_event, asOfDate=custom_datetime.isoformat()).data()\n",
    "                    temporal_note = f\"üìÖ As of: {custom_datetime}\"\n",
    "                \n",
    "                else:  # \"As of today\"\n",
    "                    query = \"\"\"\n",
    "                        MATCH fast_fw_to_future=(e:Event {event_id: $event_id})-[:COMPONENT_PARENT]->*\n",
    "                        (latest_future_comp:Event\n",
    "                        WHERE NOT EXISTS {\n",
    "                          (latest_future_comp)-[:COMPONENT_PARENT]->()\n",
    "                        }\n",
    "                        ),\n",
    "                        comp=(latest_future_comp)-[:DFS_NEXT]->*(last),\n",
    "                        (last)<-[:LAST_DFS_NODE_IN_COMP]-(latest_future_comp)\n",
    "                        UNWIND nodes(comp) AS ev\n",
    "                        RETURN {\n",
    "                            event: ev{.event_id, .border_point, .timestamp, .pattern},\n",
    "                            things: [(ev)-[r:WITH]->(x)| x{.thing_id, labels:labels(x)}]\n",
    "                        } AS events_with_things\n",
    "                    \"\"\"\n",
    "                    result = session.run(query, event_id=selected_event).data()\n",
    "                    temporal_note = f\"üìÖ As of: Now (latest)\"\n",
    "                \n",
    "                latency = (time.time() - start) * 1000\n",
    "            \n",
    "            st.success(f\"‚úÖ Retrieved in {latency:.1f}ms\")\n",
    "            st.info(temporal_note)\n",
    "            st.markdown(f\"**Component: {len(result)} events**\")\n",
    "            \n",
    "            # Parse into graph\n",
    "            nodes = []\n",
    "            edges = []\n",
    "            node_ids = set()\n",
    "            pattern_counts = Counter()\n",
    "            fraud_count = 0\n",
    "            \n",
    "            for row in result:\n",
    "                evt_data = row['events_with_things']\n",
    "                evt_id = evt_data['event']['event_id']\n",
    "                evt_pattern = evt_data['event'].get('pattern', None)\n",
    "                \n",
    "                # Track patterns\n",
    "                if evt_pattern:\n",
    "                    pattern_counts[evt_pattern] += 1\n",
    "                if is_fraud(evt_pattern):\n",
    "                    fraud_count += 1\n",
    "                \n",
    "                # Event node\n",
    "                if evt_id not in node_ids:\n",
    "                    is_selected = evt_id == selected_event\n",
    "                    color = pattern_color(evt_pattern)\n",
    "                    \n",
    "                    tooltip = f\"{evt_id}\\\\n{evt_data['event'].get('border_point', '')}\\\\n{evt_pattern or 'unknown'}\"\n",
    "                    \n",
    "                    nodes.append(Node(\n",
    "                        id=evt_id,\n",
    "                        label=evt_id.split('_')[-1][:10],\n",
    "                        size=30 if is_selected else 20,\n",
    "                        color=SELECTED_BORDER_COLOR if is_selected else color,\n",
    "                        borderWidth=3 if is_selected else 1,\n",
    "                        title=tooltip\n",
    "                    ))\n",
    "                    node_ids.add(evt_id)\n",
    "                \n",
    "                # Thing nodes\n",
    "                for thing in evt_data['things']:\n",
    "                    thing_id = thing['thing_id']\n",
    "                    if thing_id not in node_ids:\n",
    "                        labels = thing.get('labels', ['Thing'])\n",
    "                        thing_type = labels[-1] if len(labels) > 1 else 'Thing'\n",
    "                        \n",
    "                        nodes.append(Node(\n",
    "                            id=thing_id,\n",
    "                            label=thing_type[:8],\n",
    "                            size=15,\n",
    "                            color=\"#00D9FF\",\n",
    "                            shape=\"box\",\n",
    "                            title=thing_id\n",
    "                        ))\n",
    "                        node_ids.add(thing_id)\n",
    "                    \n",
    "                    edges.append(Edge(source=evt_id, target=thing_id))\n",
    "            \n",
    "            # Render graph\n",
    "            if nodes:\n",
    "                event_count = len([n for n in nodes if n.shape != \"box\"])\n",
    "                thing_count = len([n for n in nodes if n.shape == \"box\"])\n",
    "                \n",
    "                st.markdown(f\"**üìä {event_count} events, {thing_count} things**\")\n",
    "                \n",
    "                # Pattern summary\n",
    "                if fraud_count > 0:\n",
    "                    st.error(f\"üö® **{fraud_count} fraud-labeled events** in this component\")\n",
    "                \n",
    "                # Pattern breakdown\n",
    "                if pattern_counts:\n",
    "                    cols = st.columns(min(len(pattern_counts), 4))\n",
    "                    for i, (pat, count) in enumerate(pattern_counts.most_common()):\n",
    "                        with cols[i % len(cols)]:\n",
    "                            label = pat.replace(\"_\", \" \").title()\n",
    "                            color = PATTERN_COLORS.get(pat, \"#888\")\n",
    "                            st.markdown(\n",
    "                                f'<span style=\"color:{color}\">‚¨§</span> **{label}**: {count}',\n",
    "                                unsafe_allow_html=True\n",
    "                            )\n",
    "                \n",
    "                config = Config(\n",
    "                    width=900,\n",
    "                    height=600,\n",
    "                    directed=True,\n",
    "                    physics=True\n",
    "                )\n",
    "                \n",
    "                agraph(nodes=nodes, edges=edges, config=config)\n",
    "            else:\n",
    "                st.info(\"No component data\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå {e}\")\n",
    "            st.code(str(e))\n",
    "\n",
    "# Recent\n",
    "st.divider()\n",
    "with st.session_state.driver.session() as session:\n",
    "    recent = session.run(\"\"\"\n",
    "        MATCH (e:Event)\n",
    "        RETURN e.event_id AS event_id, \n",
    "               toString(e.timestamp) AS timestamp,\n",
    "               e.pattern AS pattern\n",
    "        ORDER BY e.timestamp DESC \n",
    "        LIMIT 20\n",
    "    \"\"\").data()\n",
    "st.dataframe(recent, width='stretch')\n",
    "\n",
    "st.caption(\"üï∞Ô∏è Time Machine: View how components evolved over time\")\n",
    "'''\n",
    "\n",
    "cwd = os.getcwd()\n",
    "with open('border_fraud_app.py', 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "print(f\"‚úÖ App written with Time Machine feature!\")\n",
    "print(f\"\\nThree temporal views:\")\n",
    "print(f\"  1. As of today (latest) - shows current component state\")\n",
    "print(f\"  2. As of event date - component when event occurred\")\n",
    "print(f\"  3. As of custom date - component at any point in time\")\n",
    "print(f\"\\nRun: streamlit run border_fraud_app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run border_fraud_app.py --server.headless true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
